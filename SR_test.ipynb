{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMpwXevGCVAansuHHGzObM6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MK316/SpeechProcessing/blob/main/SR_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Speech Rate"
      ],
      "metadata": {
        "id": "VSapEfVeu_Y5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition nltk mutagen\n",
        "!apt install -y ffmpeg"
      ],
      "metadata": {
        "id": "rzEPqpHVwpcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-setting: Run the following code if you have your audio file in the mp3 format"
      ],
      "metadata": {
        "id": "TNMaRJbBDefX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[1] File to upload (for converting mp3 to wav)"
      ],
      "metadata": {
        "id": "uA_okcoZw6MM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "mp3_filename = list(uploaded.keys())[0]"
      ],
      "metadata": {
        "id": "MkV4vtMawtFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[2] Converting mp3 to wav"
      ],
      "metadata": {
        "id": "csjLCar1xCkw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the WAV filename\n",
        "wav_filename = os.path.splitext(mp3_filename)[0] + \".wav\"\n",
        "\n",
        "# Convert MP3 to WAV\n",
        "!ffmpeg -i $mp3_filename $wav_filename -loglevel panic"
      ],
      "metadata": {
        "id": "_-dX_L8YDX9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[3] Audio play to check"
      ],
      "metadata": {
        "id": "xqJaKNhcxEiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio, display\n",
        "\n",
        "def play_audio(filename):\n",
        "    display(Audio(filename))\n",
        "\n",
        "# Call the function\n",
        "play_audio('2301_mono.wav')  # You can replace 'wav_filename' with your audio file's name\n"
      ],
      "metadata": {
        "id": "FvhNhW8wxapV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ”Ž **Part I: Speech rate calculation (syll/sec) with audio information**\n",
        "\n",
        "The following codes will collect the information below:\n",
        "\n",
        "+ Filename\n",
        "+ Text (from speech recognition)\n",
        "+ Duration (audio duration)\n",
        "+ Number of words\n",
        "+ Number of syllables\n",
        "+ Averaged number of syllables per word\n",
        "+ WPM (Word per minute): number of words per minute\n",
        "+ SR (Speech rate): number of syllables per second\n",
        "\n",
        "**Note: Run [1a] or [1b] to read audio files:**\n",
        "\n",
        "[1a] Audio zip file from Google Drive  \n",
        "[1b] Audio zip file from your computer  \n",
        "\n",
        "**Then, move to [2] to get the audio information**  \n",
        "\n",
        "[2] Getting SR and record the information"
      ],
      "metadata": {
        "id": "wHn47g-556Lz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [1a] Audio files (one zip file) from your Google Drive"
      ],
      "metadata": {
        "id": "kIlNtRGK9Za9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "Qp_NSN8G5-vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Specify the path to the zip file in Google Drive (replace with your actual path)\n",
        "zip_path = \"/content/drive/MyDrive/SNSR/test.zip\"\n",
        "\n",
        "# 3. Create a temporary directory for unzipping\n",
        "unzip_dir = \"/content/temp_unzip_folder/\"\n",
        "os.makedirs(unzip_dir, exist_ok=True)\n",
        "\n",
        "# Unzip the file\n",
        "!unzip -q $zip_path -d $unzip_dir\n",
        "\n",
        "# 4. Copy the extracted files to \"myaudio\" folder\n",
        "myaudio_path = \"/content/myaudio/\"\n",
        "os.makedirs(myaudio_path, exist_ok=True)\n",
        "\n",
        "for item in os.listdir(unzip_dir):\n",
        "    shutil.move(os.path.join(unzip_dir, item), os.path.join(myaudio_path, item))\n",
        "\n",
        "# Clean up by removing the temporary directory\n",
        "shutil.rmtree(unzip_dir)\n"
      ],
      "metadata": {
        "id": "GzLop0HR5569"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "EIrFsbruQuFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [1b] Audio files (one zip file) from your computer"
      ],
      "metadata": {
        "id": "pvnks386-vPV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "# 1. Upload a zip file\n",
        "uploaded = files.upload()\n",
        "zip_filename = list(uploaded.keys())[0]\n",
        "\n",
        "# 2. Create a folder named 'myaudio'\n",
        "if not os.path.exists('myaudio'):\n",
        "    os.makedirs('myaudio')\n",
        "\n",
        "# 3. Unzip the uploaded files\n",
        "with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
        "    zip_ref.extractall('temp_unzip_folder')\n",
        "\n",
        "# 4. Move the unzipped files to the 'myaudio' folder\n",
        "for item in os.listdir('temp_unzip_folder'):\n",
        "    shutil.move(os.path.join('temp_unzip_folder', item), 'myaudio')\n",
        "\n",
        "# Cleanup: remove the temporary unzip folder\n",
        "shutil.rmtree('temp_unzip_folder')\n",
        "\n",
        "# 5. Remove the zip file\n",
        "os.remove(zip_filename)\n"
      ],
      "metadata": {
        "id": "yMhL8gvP-yrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [2] Getting SR and record the information in a dataframe"
      ],
      "metadata": {
        "id": "ojj3VC3p_L1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import speech_recognition as sr\n",
        "from nltk.corpus import cmudict\n",
        "import nltk\n",
        "import mutagen\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('cmudict')\n",
        "\n",
        "# Initialize CMU dictionary\n",
        "d = cmudict.dict()\n",
        "\n",
        "# Functions for syllable and text metrics\n",
        "def nsyl(word):\n",
        "    if word.lower() in d:\n",
        "        return max([len([y for y in x if y[-1].isdigit()]) for x in d[word.lower()]])\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def text_metrics(text):\n",
        "    words = nltk.word_tokenize(text)\n",
        "    total_words = len(words)\n",
        "    total_syllables = sum(nsyl(word) for word in words)\n",
        "    avg_syllables = total_syllables / total_words if total_words != 0 else 0\n",
        "    return total_words, total_syllables, avg_syllables\n",
        "\n",
        "# Initialize speech recognizer\n",
        "r = sr.Recognizer()\n",
        "\n",
        "# List .wav files from myaudio folder\n",
        "wav_files = [f for f in os.listdir('myaudio') if f.endswith('.wav')]\n",
        "\n",
        "results = []\n",
        "\n",
        "# Process each .wav file\n",
        "for wav_file in wav_files:\n",
        "    # 2. Transcribe audio\n",
        "    with sr.AudioFile(os.path.join('myaudio', wav_file)) as source:\n",
        "        audio_data = r.record(source)\n",
        "        try:\n",
        "            text = r.recognize_google(audio_data)\n",
        "        except sr.UnknownValueError:\n",
        "            print(f\"Could not understand audio {wav_file}\")\n",
        "            text = \"\"\n",
        "        except sr.RequestError:\n",
        "            print(f\"API unavailable for {wav_file}\")\n",
        "            text = \"\"\n",
        "\n",
        "    # 3. Calculate metrics\n",
        "    total_words, total_syllables, avg_syllables = text_metrics(text)\n",
        "\n",
        "    audio = mutagen.File(os.path.join('myaudio', wav_file))\n",
        "    duration = audio.info.length\n",
        "    speech_rate = total_syllables / duration if duration != 0 else 0\n",
        "    speech_rate_wpm = (total_words / duration) * 60 if duration != 0 else 0\n",
        "\n",
        "    # Append results\n",
        "    results.append({\n",
        "        'Filename': wav_file,\n",
        "        'Text': text,\n",
        "        'Duration': duration,\n",
        "        'Nwords': total_words,\n",
        "        'Nsyll': total_syllables,\n",
        "        'Avg_syll': avg_syllables,\n",
        "        'WPM': speech_rate_wpm,\n",
        "        'SR': speech_rate\n",
        "\n",
        "    })\n",
        "\n",
        "# 4. Create DataFrame\n",
        "df = pd.DataFrame(results)\n",
        "df\n"
      ],
      "metadata": {
        "id": "Un2cNdu18Wi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ”Ž **Part II Silence proportion**"
      ],
      "metadata": {
        "id": "E2w4pAfEEhiG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explore silence portion in the given audio file (all files under myaudio folder)"
      ],
      "metadata": {
        "id": "ywb2w2JQMrYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the necessary libraries\n",
        "!pip install pydub\n",
        "!apt install -y ffmpeg\n",
        "\n",
        "import os\n",
        "from pydub import AudioSegment\n",
        "from pydub.silence import detect_silence\n",
        "\n",
        "audio_folder = '/content/myaudio'\n",
        "\n",
        "# Loop through each audio file in `/content/myaudio` directory.\n",
        "for audio_file in os.listdir(audio_folder):\n",
        "    if audio_file.endswith(\".wav\"):  # Ensuring we only process .wav files\n",
        "        audio_path = os.path.join(audio_folder, audio_file)\n",
        "        audio = AudioSegment.from_wav(audio_path)\n",
        "\n",
        "        # Detect silence - considering a chunk as silence if quieter than -40 dBFS for more than 1000 ms (1 second).\n",
        "        silence_chunks = detect_silence(audio, min_silence_len=1000, silence_thresh=-40)\n",
        "\n",
        "        # Calculate total silence duration\n",
        "        total_silence_duration = sum([(end - start) for (start, end) in silence_chunks])\n",
        "\n",
        "        # Calculate proportion of silence\n",
        "        total_audio_duration = len(audio)\n",
        "        silence_proportion = total_silence_duration / total_audio_duration\n",
        "\n",
        "        print(f\"Audio File: {audio_file}\")\n",
        "        print(f\"Total silence duration: {total_silence_duration} ms\")\n",
        "        print(f\"Proportion of silence in the audio: {silence_proportion:.2%}\")\n",
        "        print(\"---------------------------------------------------\")\n",
        "\n"
      ],
      "metadata": {
        "id": "jsSjbt9LEs0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ðŸ”Ž **Part III. Combined all in one dataframe**\n",
        "\n",
        "When running the code below, we get the results from Part I and Part II together."
      ],
      "metadata": {
        "id": "wixbO8M6TxVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import speech_recognition as sr\n",
        "from nltk.corpus import cmudict\n",
        "import nltk\n",
        "import mutagen\n",
        "from pydub import AudioSegment, silence\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('cmudict')\n",
        "\n",
        "# Initialize CMU dictionary\n",
        "d = cmudict.dict()\n",
        "\n",
        "# Functions for syllable and text metrics\n",
        "def nsyl(word):\n",
        "    if word.lower() in d:\n",
        "        return max([len([y for y in x if y[-1].isdigit()]) for x in d[word.lower()]])\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def text_metrics(text):\n",
        "    words = nltk.word_tokenize(text)\n",
        "    total_words = len(words)\n",
        "    total_syllables = sum(nsyl(word) for word in words)\n",
        "    avg_syllables = total_syllables / total_words if total_words != 0 else 0\n",
        "    return total_words, total_syllables, avg_syllables\n",
        "\n",
        "# Initialize speech recognizer\n",
        "r = sr.Recognizer()\n",
        "\n",
        "# List .wav files from myaudio folder\n",
        "wav_files = [f for f in os.listdir('/content/myaudio') if f.endswith('.wav')]\n",
        "\n",
        "results = []\n",
        "\n",
        "# Process each .wav file\n",
        "for wav_file in wav_files:\n",
        "    # Load the audio\n",
        "    audio_path = os.path.join('/content/myaudio', wav_file)\n",
        "    audio = AudioSegment.from_wav(audio_path)\n",
        "    silence_chunks = silence.detect_silence(audio, min_silence_len=1000, silence_thresh=-40)\n",
        "    total_silence_duration = sum([(end - start) for (start, end) in silence_chunks])\n",
        "    total_silence_duration_sec = sum([(end - start) for (start, end) in silence_chunks]) / 1000.0\n",
        "\n",
        "    silence_proportion = (total_silence_duration / len(audio))*100\n",
        "\n",
        "    # 2. Transcribe audio\n",
        "    with sr.AudioFile(audio_path) as source:\n",
        "        audio_data = r.record(source)\n",
        "        try:\n",
        "            text = r.recognize_google(audio_data)\n",
        "        except sr.UnknownValueError:\n",
        "            print(f\"Could not understand audio {wav_file}\")\n",
        "            text = \"\"\n",
        "        except sr.RequestError:\n",
        "            print(f\"API unavailable for {wav_file}\")\n",
        "            text = \"\"\n",
        "\n",
        "    # 3. Calculate metrics\n",
        "    total_words, total_syllables, avg_syllables = text_metrics(text)\n",
        "\n",
        "    audio_meta = mutagen.File(audio_path)\n",
        "    duration = audio_meta.info.length\n",
        "    speech_rate = total_syllables / duration if duration != 0 else 0\n",
        "    speech_rate_wpm = (total_words / duration) * 60 if duration != 0 else 0\n",
        "\n",
        "    # Append results\n",
        "    results.append({\n",
        "        'Filename': wav_file,\n",
        "        'Text': text,\n",
        "        'Duration': duration,\n",
        "        'Nwords': total_words,\n",
        "        'Nsyll': total_syllables,\n",
        "        'Avg_syll': avg_syllables,\n",
        "        'WPM': speech_rate_wpm,\n",
        "        'SR': speech_rate,\n",
        "        'Silence_Duration_sec': total_silence_duration_sec,\n",
        "        'Proportion_of_Silence': silence_proportion\n",
        "    })\n",
        "\n",
        "# 4. Create DataFrame\n",
        "df = pd.DataFrame(results)\n",
        "df\n"
      ],
      "metadata": {
        "id": "ln2QluMlT1Le"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}